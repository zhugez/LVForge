"""Base Flax LVModel for PE malware detection."""

import jax.numpy as jnp
import flax.linen as nn
from flax.linen import initializers

from .transformer import FlaxTransformerLayer


class FlaxLVModel(nn.Module):
    """Custom Transformer classifier for PE malware detection (Flax)."""

    vocab_size: int
    embed_dim: int = 128
    num_heads: int = 4
    ff_dim: int = 256
    num_layers: int = 6
    num_classes: int = 2
    max_seq_len: int = 380
    dropout_rate: float = 0.1

    def setup(self):
        embed_init = initializers.normal(stddev=0.02)
        kernel_init = initializers.variance_scaling(1.0, "fan_avg", "truncated_normal")

        self.embedding = nn.Embed(
            num_embeddings=self.vocab_size,
            features=self.embed_dim,
            embedding_init=embed_init,
        )
        self.pos_embed = nn.Embed(
            num_embeddings=self.max_seq_len,
            features=self.embed_dim,
            embedding_init=embed_init,
        )

        self.encoder_layers = [
            FlaxTransformerLayer(
                embed_dim=self.embed_dim,
                num_heads=self.num_heads,
                ff_dim=self.ff_dim,
                dropout=self.dropout_rate,
            )
            for _ in range(self.num_layers)
        ]

        self.pooler = nn.Dense(self.embed_dim, kernel_init=kernel_init)
        self.pooler_activation = nn.tanh
        self.pooler_dropout = nn.Dropout(rate=0.1)

        self.classifier_norm = nn.LayerNorm()
        self.classifier = nn.Dense(self.num_classes, kernel_init=kernel_init)

        self.dropout = nn.Dropout(rate=self.dropout_rate)

    @nn.compact
    def __call__(self, input_ids, train: bool = True):
        seq_len = input_ids.shape[1]
        positions = jnp.arange(seq_len)[None, :].repeat(input_ids.shape[0], axis=0)

        x = self.embedding(input_ids) + self.pos_embed(positions)

        for layer in self.encoder_layers:
            x = layer(x, train=train)

        pooled = jnp.mean(x, axis=1)
        pooled = self.pooler(pooled)
        pooled = self.pooler_activation(pooled)
        pooled = self.pooler_dropout(pooled, deterministic=not train)

        logits = self.classifier(self.classifier_norm(pooled))
        return logits
